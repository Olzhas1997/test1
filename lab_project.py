# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DJVufrFD_ovNmbrhCO71_1cnlwDx3jWX
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install transformers==4.10.3

import torch
import numpy as np
import transformers
from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader
from transformers import GPT2LMHeadModel, GPT2Tokenizer

model_name = "sberbank-ai/mGPT"

tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

story_begin = input("Введите начало вашей истории: ")

model.cuda()
model.eval()
input_ids = tokenizer.encode(story_begin, return_tensors="pt").cuda()
out = model.generate(
        input_ids, 
        min_length=100, 
        max_length=100, 
        eos_token_id=5, 
        pad_token=1,
        top_k=10,
        top_p=0.0,
        no_repeat_ngram_size=5
)

generated_text = list(map(tokenizer.decode, out))[0]
print(generated_text)